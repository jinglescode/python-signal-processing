{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "import sys\n",
    "path = os.path.join(cwd, \"..\\\\..\\\\\")\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import logging\n",
    "logging.getLogger('lightning').setLevel(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pytorch_lightning\n",
    "pytorch_lightning.utilities.distributed.log.setLevel(logging.ERROR)\n",
    "\n",
    "from splearn.data import MultipleSubjects, PyTorchDataset, PyTorchDataset2Views, HSSSVEP\n",
    "from splearn.filter.butterworth import butter_bandpass_filter\n",
    "from splearn.filter.notch import notch_filter\n",
    "from splearn.filter.channels import pick_channels\n",
    "from splearn.nn.models import CompactEEGNet\n",
    "from splearn.utils import Logger, Config\n",
    "from splearn.nn.base import LightningModelClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"run_name\": \"eeg_hsssvep_run2\",\n",
    "    \"data\": {\n",
    "        \"load_subject_ids\": np.arange(1,36),\n",
    "        # \"selected_channels\": [\"PO8\", \"PZ\", \"PO7\", \"PO4\", \"POz\", \"PO3\", \"O2\", \"Oz\", \"O1\"], # AA paper\n",
    "        \"selected_channels\": [\"PZ\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"O1\", \"Oz\", \"O2\"], # hsssvep paper\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"num_epochs\": 500,\n",
    "        \"num_warmup_epochs\": 50,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"gpus\": [0],\n",
    "        \"batchsize\": 256,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"optimizer\": \"adamw\",\n",
    "        \"scheduler\": \"cosine_with_warmup\",\n",
    "    },\n",
    "    \"testing\": {\n",
    "        \"test_subject_ids\": np.arange(33,34),\n",
    "        \"kfolds\": np.arange(0,3),\n",
    "    },\n",
    "    \"seed\": 1234\n",
    "}\n",
    "\n",
    "main_logger = Logger(filename_postfix=config[\"run_name\"])\n",
    "main_logger.write_to_log(\"Config\")\n",
    "main_logger.write_to_log(config)\n",
    "\n",
    "config = Config(config)\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load subject: 1\n",
      "Load subject: 2\n",
      "Load subject: 3\n",
      "Load subject: 4\n",
      "Load subject: 5\n",
      "Load subject: 6\n",
      "Load subject: 7\n",
      "Load subject: 8\n",
      "Load subject: 9\n",
      "Load subject: 10\n",
      "Load subject: 11\n",
      "Load subject: 12\n",
      "Load subject: 13\n",
      "Load subject: 14\n",
      "Load subject: 15\n",
      "Load subject: 16\n",
      "Load subject: 17\n",
      "Load subject: 18\n",
      "Load subject: 19\n",
      "Load subject: 20\n",
      "Load subject: 21\n",
      "Load subject: 22\n",
      "Load subject: 23\n",
      "Load subject: 24\n",
      "Load subject: 25\n",
      "Load subject: 26\n",
      "Load subject: 27\n",
      "Load subject: 28\n",
      "Load subject: 29\n",
      "Load subject: 30\n",
      "Load subject: 31\n",
      "Load subject: 32\n",
      "Load subject: 33\n",
      "Load subject: 34\n",
      "Load subject: 35\n"
     ]
    }
   ],
   "source": [
    "def func_preprocessing(data):\n",
    "    data_x = data.data\n",
    "    data_x = pick_channels(data_x, channel_names=data.channel_names, selected_channels=config.data.selected_channels)\n",
    "    # data_x = notch_filter(data_x, sampling_rate=data.sampling_rate, notch_freq=50.0)\n",
    "    data_x = butter_bandpass_filter(data_x, lowcut=7, highcut=90, sampling_rate=data.sampling_rate, order=6)\n",
    "    start_t = 160\n",
    "    end_t = start_t + 250\n",
    "    data_x = data_x[:,:,:,start_t:end_t]\n",
    "    data.set_data(data_x)\n",
    "\n",
    "data = MultipleSubjects(\n",
    "    dataset=HSSSVEP, \n",
    "    root=os.path.join(path, \"../data/hsssvep\"), \n",
    "    subject_ids=config.data.load_subject_ids, \n",
    "    func_preprocessing=func_preprocessing,\n",
    "    verbose=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data shape: (35, 240, 9, 250)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final data shape:\", data.data.shape)\n",
    "\n",
    "num_channel = data.data.shape[2]\n",
    "num_classes = 40\n",
    "signal_length = data.data.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subject_id=1\n",
    "kfold_k=1\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = data.get_train_val_test_dataset(test_subject_id=test_subject_id, kfold_k=kfold_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 9, 250)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_subject_kfold(data, config, test_subject_id, kfold_k=0):\n",
    "    \n",
    "    ## init data\n",
    "    \n",
    "    # train_dataset, val_dataset, test_dataset = leave_one_subject_out(data, test_subject_id=test_subject_id, kfold_k=kfold_k)\n",
    "    train_dataset, val_dataset, test_dataset = data.get_train_val_test_dataset(test_subject_id=test_subject_id, kfold_k=kfold_k)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.training.batchsize, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.training.batchsize, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.training.batchsize, shuffle=False)\n",
    "\n",
    "    ## init model\n",
    "\n",
    "    eegnet = CompactEEGNet(num_channel=num_channel, num_classes=num_classes, signal_length=signal_length)\n",
    "\n",
    "    model = LightningModelClassifier(\n",
    "        optimizer=config.model.optimizer,\n",
    "        scheduler=config.model.scheduler,\n",
    "        optimizer_learning_rate=config.training.learning_rate,\n",
    "        scheduler_warmup_epochs=config.training.num_warmup_epochs,\n",
    "    )\n",
    "    \n",
    "    model.build_model(model=eegnet)\n",
    "\n",
    "    ## train\n",
    "\n",
    "    sub_dir = \"sub\"+ str(test_subject_id) +\"_k\"+ str(kfold_k)\n",
    "    logger_tb = TensorBoardLogger(save_dir=\"tensorboard_logs\", name=config.run_name, sub_dir=sub_dir)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "    trainer = Trainer(max_epochs=config.training.num_epochs, gpus=config.training.gpus, logger=logger_tb, progress_bar_refresh_rate=0, weights_summary=None, callbacks=[lr_monitor])\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    ## test\n",
    "    \n",
    "    result = trainer.test(dataloaders=test_loader, verbose=False)\n",
    "    test_acc = result[0]['test_acc_epoch']\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running test_subject_id: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_subject_id': 1, 'acc': [0.5916666388511658]}\n",
      "\n",
      "mean all 0.5916666388511658\n"
     ]
    }
   ],
   "source": [
    "main_logger.write_to_log(\"Begin\", break_line=True)\n",
    "\n",
    "test_results_acc = {}\n",
    "means = []\n",
    "\n",
    "def k_fold_train_test_all_subjects():\n",
    "    \n",
    "    for test_subject_id in config.testing.test_subject_ids:\n",
    "        print()\n",
    "        print(\"running test_subject_id:\", test_subject_id)\n",
    "        \n",
    "        if test_subject_id not in test_results_acc:\n",
    "            test_results_acc[test_subject_id] = []\n",
    "        \n",
    "        test_acc = train_test_subject_kfold(data, config, test_subject_id, kfold_k=0)\n",
    "            \n",
    "        test_results_acc[test_subject_id].append(test_acc)\n",
    "        means.append(test_acc)\n",
    "        \n",
    "        this_result = {\n",
    "            \"test_subject_id\": test_subject_id,\n",
    "            \"acc\": test_results_acc[test_subject_id],\n",
    "        }        \n",
    "        print(this_result)\n",
    "        main_logger.write_to_log(this_result)\n",
    "\n",
    "        \n",
    "k_fold_train_test_all_subjects()\n",
    "\n",
    "mean_acc = np.mean(means)\n",
    "print()\n",
    "print(\"mean all\", mean_acc)\n",
    "main_logger.write_to_log(\"Mean acc: \"+str(mean_acc), break_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splearn.nn.modules.conv2d import Conv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(320, 9, 250)\n",
    "\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# model = CompactEEGNet(num_channel=num_channel, num_classes=num_classes, signal_length=signal_length)\n",
    "# y = model(x)\n",
    "# print(y.shape)\n",
    "\n",
    "# model = Model()\n",
    "# y = model(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SlowFast(nn.Module):\n",
    "#     def __init__(self, block=None, layers=[3, 4, 6, 3], class_num=10, dropout=0.5):\n",
    "#         super(SlowFast, self).__init__()\n",
    "\n",
    "#         in_channels = 9\n",
    "#         filters = [32, 64, 128]\n",
    "#         kernel_size = (1, 5)\n",
    "\n",
    "#         self.fast_conv1 = Conv2d(\n",
    "#             in_channels, filters[0], kernel_size=kernel_size, bias=False)\n",
    "#         self.fast_bn1 = nn.BatchNorm2d(filters[0])\n",
    "#         self.fast_conv2 = Conv2d(\n",
    "#             filters[0], filters[1], kernel_size=kernel_size, bias=False)\n",
    "#         self.fast_bn2 = nn.BatchNorm2d(filters[1])\n",
    "#         self.fast_conv3 = Conv2d(\n",
    "#             filters[1], filters[2], kernel_size=kernel_size, bias=False)\n",
    "#         self.fast_bn3 = nn.BatchNorm2d(filters[2])\n",
    "\n",
    "#         self.fast_relu = nn.ReLU(inplace=True)\n",
    "#         self.fast_maxpool = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1))\n",
    "\n",
    "#         self.lateral_p1 = Conv2d(\n",
    "#             filters[0], filters[0], kernel_size=(1, 1), stride=(1, 2), bias=False)\n",
    "#         self.lateral_p2 = Conv2d(\n",
    "#             filters[1], filters[1], kernel_size=(1, 1), stride=(1, 2), bias=False)\n",
    "#         self.lateral_p3 = Conv2d(\n",
    "#             filters[2], filters[2], kernel_size=(1, 1), stride=(1, 2), bias=False)\n",
    "        \n",
    "#         self.identity1 = Conv2d(\n",
    "#             in_channels, filters[0], kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#         self.identity2 = Conv2d(\n",
    "#             filters[0], filters[1], kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#         self.identity3 = Conv2d(\n",
    "#             filters[1], filters[2], kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "\n",
    "#         self.slow_conv1 = Conv2d(\n",
    "#             in_channels, filters[0], kernel_size=kernel_size, stride=(1, 2), padding=(0, 3), bias=False)\n",
    "#         self.slow_bn1 = nn.BatchNorm2d(filters[0])\n",
    "#         self.slow_conv2 = Conv2d(\n",
    "#             filters[1], filters[1], kernel_size=kernel_size, stride=(1, 2), padding=(0, 3), bias=False)\n",
    "#         self.slow_bn2 = nn.BatchNorm2d(filters[1])\n",
    "#         self.slow_conv3 = Conv2d(\n",
    "#             filters[2], filters[2], kernel_size=kernel_size, stride=(1, 2), padding=(0, 3), bias=False)\n",
    "#         self.slow_bn3 = nn.BatchNorm2d(filters[2])\n",
    "\n",
    "#         self.slow_relu = nn.ReLU(inplace=True)\n",
    "#         self.slow_maxpool = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1))\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         input = torch.unsqueeze(input, 2)\n",
    "#         fast, lateral = self.FastPath(input)\n",
    "#         slow = self.SlowPath(input, lateral)\n",
    "#         return fast, slow\n",
    "\n",
    "#     def SlowPath(self, input, lateral):\n",
    "#         x = self.slow_conv1(input)\n",
    "#         x = self.slow_bn1(x)\n",
    "#         x = self.slow_relu(x)\n",
    "#         x = self.slow_maxpool(x)\n",
    "#         # print(\"slow x\", x.shape, lateral[0].shape)\n",
    "#         x = torch.cat([x, lateral[0]], dim=1)\n",
    "        \n",
    "#         # print(\"slow x\", x.shape)\n",
    "#         x = self.slow_conv2(x)\n",
    "#         x = self.slow_bn2(x)\n",
    "#         x = self.slow_relu(x)\n",
    "#         x = self.slow_maxpool(x)\n",
    "#         # print(\"slow x\", x.shape, lateral[1].shape)\n",
    "#         x = torch.cat([x, lateral[1]], dim=1)\n",
    "\n",
    "#         # print(\"slow x\", x.shape)\n",
    "#         x = self.slow_conv3(x)\n",
    "#         x = self.slow_bn3(x)\n",
    "#         x = self.slow_relu(x)\n",
    "#         x = self.slow_maxpool(x)\n",
    "#         # print(\"slow x\", x.shape, lateral[2].shape)\n",
    "#         x = torch.cat([x, lateral[2]], dim=1)\n",
    "\n",
    "#         return x\n",
    "\n",
    "#     def FastPath(self, input):\n",
    "#         lateral = []\n",
    "#         x1 = self.fast_conv1(input)\n",
    "#         x1 = self.fast_bn1(x1)\n",
    "#         x1 = self.fast_relu(x1)\n",
    "#         x1 = self.identity1(input) + x1\n",
    "#         # pool1 = self.fast_maxpool(x1)\n",
    "#         # print(\"pool1\", pool1.shape)\n",
    "#         # print(\"x1\", x1.shape)\n",
    "#         lateral_p1 = self.lateral_p1(x1)\n",
    "#         lateral.append(lateral_p1)\n",
    "#         # print(\"lateral_p1\", lateral_p1.shape)\n",
    "\n",
    "#         x2 = self.fast_conv2(lateral_p1)\n",
    "#         x2 = self.fast_bn2(x2)\n",
    "#         x2 = self.fast_relu(x2)\n",
    "#         x2 = self.identity2(lateral_p1) + x2\n",
    "#         # print(lateral_p1.shape, x2.shape)\n",
    "#         # x2 = lateral_p1 + x2\n",
    "#         # pool2 = self.fast_maxpool(x2)\n",
    "#         # print(\"pool2\", pool2.shape)\n",
    "#         # print(\"x2\", x2.shape)\n",
    "#         lateral_p2 = self.lateral_p2(x2)\n",
    "#         # print(\"lateral_p2\", lateral_p2.shape)\n",
    "#         lateral.append(lateral_p2)\n",
    "\n",
    "#         x3 = self.fast_conv3(lateral_p2)\n",
    "#         x3 = self.fast_bn3(x3)\n",
    "#         x3 = self.fast_relu(x3)\n",
    "#         x3 = self.identity3(lateral_p2) + x3\n",
    "#         # x3 = lateral_p2 + x3\n",
    "#         # pool3 = self.fast_maxpool(x3)\n",
    "#         # print(\"pool3\", pool3.shape)\n",
    "#         # print(\"x3\", x3.shape)\n",
    "#         lateral_p3 = self.lateral_p3(x3)\n",
    "#         # print(\"lateral_p3\", lateral_p3.shape)\n",
    "#         lateral.append(lateral_p3)\n",
    "\n",
    "#         return lateral_p3, lateral\n",
    "\n",
    "\n",
    "# model = SlowFast()\n",
    "# fast, slow = model(x)\n",
    "# print(\"fast\", fast.shape)\n",
    "# print(\"slow\", slow.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow 1 torch.Size([320, 32, 4, 112])\n",
      "slow fusion1 torch.Size([320, 32, 4, 112]) torch.Size([320, 8, 32, 112])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 4, 1, 3], expected input[320, 8, 32, 112] to have 4 channels, but got 8 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a0966bd19610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSlowFast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m \u001b[0mfast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fast\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-a0966bd19610>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# print(\"input.shape\", input.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mfast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlateral\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFastPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mslow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSlowPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlateral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-a0966bd19610>\u001b[0m in \u001b[0;36mSlowPath\u001b[1;34m(self, input, lateral)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"slow fusion1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlateral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfusion1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlateral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-a0966bd19610>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mx_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# print(888, x_f.shape) # 888 torch.Size([320, 64, 32, 56])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mfuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_fast_to_slow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mfuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mfuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 4, 1, 3], expected input[320, 8, 32, 112] to have 4 channels, but got 8 channels instead"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2d(\n",
    "            in_channels, out_channels, kernel_size=kernel_size, stride=stride, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, kernel_sizes):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = Block(in_channels=in_channels, out_channels=hidden_channels, kernel_size=kernel_sizes[0])\n",
    "        self.conv2 = Block(in_channels=hidden_channels, out_channels=hidden_channels, kernel_size=kernel_sizes[1])\n",
    "        self.conv3 = Block(in_channels=hidden_channels, out_channels=out_channels, kernel_size=kernel_sizes[2])\n",
    "        self.conv_fusion = Conv2d(\n",
    "            in_channels=in_channels, out_channels=out_channels, kernel_size=(1,1), bias=False)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        # print(\"ResBlock 1\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print(\"ResBlock 2\", x.shape)\n",
    "        x = self.conv3(x)\n",
    "        # print(\"ResBlock 3\", x.shape)\n",
    "        \n",
    "        shortcut = self.conv_fusion(input)\n",
    "        # print(\"shortcut\", shortcut.shape)\n",
    "        \n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n",
    "class Fusion(nn.Module):\n",
    "    def __init__(self, fusion_dim_in, conv_kernel_size, conv_stride, slowfast_channel_reduction_ratio=8, conv_fusion_channel_ratio=8):\n",
    "        super(Fusion, self).__init__()\n",
    "        \n",
    "        conv_dim_in = fusion_dim_in // slowfast_channel_reduction_ratio\n",
    "        norm_eps = 1e-5\n",
    "        norm_momentum = 0.1\n",
    "        \n",
    "        self.conv_fast_to_slow = nn.Conv2d(\n",
    "            conv_dim_in,\n",
    "            int(conv_dim_in * conv_fusion_channel_ratio),\n",
    "            kernel_size=conv_kernel_size,\n",
    "            stride=conv_stride,\n",
    "            padding=[k_size // 2 for k_size in conv_kernel_size],\n",
    "            bias=False,\n",
    "        )\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(\n",
    "            num_features=conv_dim_in * conv_fusion_channel_ratio,\n",
    "            eps=norm_eps,\n",
    "            momentum=norm_momentum,\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_s = x[0]\n",
    "        x_f = x[1]\n",
    "        # print(888, x_f.shape) # 888 torch.Size([320, 64, 32, 56])\n",
    "        fuse = self.conv_fast_to_slow(x_f)\n",
    "        fuse = self.bn(fuse)\n",
    "        fuse = self.activation(fuse)\n",
    "        x_s_fuse = torch.cat([x_s, fuse], 1)\n",
    "        return x_s_fuse\n",
    "\n",
    "\n",
    "class SlowFast(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SlowFast, self).__init__()\n",
    "        in_channels = 1\n",
    "        \n",
    "        self.fast_conv1 = Block(in_channels=in_channels, out_channels=8, kernel_size=(5,7), stride=(2,2))\n",
    "        self.fast_maxpool = nn.MaxPool2d(kernel_size=(1,3), stride=(1,2), padding=(0,1))\n",
    "        \n",
    "        self.fast_conv2 = ResBlock(in_channels=8, hidden_channels=8, out_channels=32, kernel_sizes=[(3,1),(1,3),(1,1)])\n",
    "        self.fast_conv3 = ResBlock(in_channels=32, hidden_channels=16, out_channels=64, kernel_sizes=[(3,1),(1,3),(1,1)])\n",
    "        \n",
    "        self.slow_conv1 = Block(in_channels=in_channels, out_channels=32, kernel_size=(1,7), stride=(16,2))\n",
    "        self.slow_maxpool = nn.MaxPool2d(kernel_size=(1,3), stride=(1,2), padding=(0,1))\n",
    "        \n",
    "        self.slow_conv2 = ResBlock(in_channels=64, hidden_channels=64, out_channels=256, kernel_sizes=[(1,1),(1,3),(1,1)])\n",
    "        self.slow_conv3 = ResBlock(in_channels=256, hidden_channels=128, out_channels=512, kernel_sizes=[(1,1),(1,3),(1,1)])\n",
    "        \n",
    "        self.fusion1 = Fusion(fusion_dim_in=32, conv_kernel_size=(1,3), conv_stride=(8,1))\n",
    "        self.fusion2 = Fusion(fusion_dim_in=128, conv_kernel_size=(1,3), conv_stride=(8,1))\n",
    "        self.fusion3 = Fusion(fusion_dim_in=256, conv_kernel_size=(1,3), conv_stride=(8,1))\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        # input = torch.unsqueeze(input, 3)\n",
    "        # print(\"input.shape\", input.shape)\n",
    "        fast, lateral = self.FastPath(input)        \n",
    "        slow = self.SlowPath(input, lateral)\n",
    "        return fast, slow\n",
    "\n",
    "    \n",
    "    def FastPath(self, input):\n",
    "        lateral = []\n",
    "        x1 = self.fast_conv1(input)\n",
    "        # x1 = self.fast_maxpool(x1)\n",
    "        # print(\"fast x1\", x1.shape)\n",
    "        lateral.append(x1)\n",
    "        \n",
    "        x2 = self.fast_conv2(x1)\n",
    "        # print(\"fast x2\", x2.shape)\n",
    "        lateral.append(x2)\n",
    "        \n",
    "        x3 = self.fast_conv3(x2)\n",
    "        # print(\"fast x3\", x3.shape)\n",
    "        lateral.append(x3)\n",
    "        \n",
    "        return x3, lateral\n",
    "    \n",
    "    def SlowPath(self, input, lateral):\n",
    "        x1 = self.slow_conv1(input)\n",
    "        # x1 = self.slow_maxpool(x1)\n",
    "        print(\"slow 1\", x1.shape)\n",
    "        \n",
    "        print(\"slow fusion1\",x1.shape, lateral[0].shape)\n",
    "        x1 = self.fusion1([x1, lateral[0]])\n",
    "        \n",
    "        \n",
    "        x2 = self.slow_conv2(x1)\n",
    "        print(\"slow fusion2\", x2.shape, lateral[1].shape)\n",
    "        x2 = self.fusion2([x2,lateral[1]])\n",
    "        \n",
    "        \n",
    "        x3 = self.slow_conv3(x2)\n",
    "        print(\"slow fusion3\", x3.shape, lateral[2].shape)\n",
    "        x3 = self.fusion3([x3,lateral[2]])\n",
    "        \n",
    "\n",
    "        return x3\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn(320, 1, 64, 224)\n",
    "\n",
    "model = SlowFast()\n",
    "fast, slow = model(x)\n",
    "print()\n",
    "print(\"fast\", fast.shape)\n",
    "print(\"slow\", slow.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 1088, 15, 1])\n",
      "torch.Size([320, 40])\n"
     ]
    }
   ],
   "source": [
    "# class Detection(nn.Module):\n",
    "\n",
    "#     # def __init__(self, pooler_mode: Pooler.Mode, hidden: nn.Module, num_hidden_out: int, num_classes: int, proposal_smooth_l1_loss_beta: float):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         num_hidden_out = 12288\n",
    "#         num_classes = 40\n",
    "#         self._proposal_class = nn.Linear(num_hidden_out, num_classes)\n",
    "\n",
    "#     def forward(self, fast_feature, slow_feature):\n",
    "#         batch_size = fast_feature.shape[0]\n",
    "        \n",
    "#         fast_feature = nn.AvgPool2d(kernel_size=(\n",
    "#             fast_feature.shape[2], 1))(fast_feature).squeeze(2)\n",
    "#         # print(fast_feature.shape)\n",
    "#         slow_feature = nn.AvgPool2d(kernel_size=(\n",
    "#             slow_feature.shape[2], 1))(slow_feature).squeeze(2)\n",
    "#         # print(slow_feature.shape)\n",
    "#         feature = torch.cat([fast_feature, slow_feature], dim=1)\n",
    "#         # print(feature.shape)\n",
    "\n",
    "#         out = feature.view(feature.shape[0],-1)#.cuda()\n",
    "#         # out = torch.flatten(feature, start_dim=1)\n",
    "#         # out = torch.reshape(feature,(feature.shape[0],-1))\n",
    "#         # print(out.shape)\n",
    "#         proposal_classes = self._proposal_class(out)\n",
    "#         # print(proposal_classes.shape)\n",
    "        \n",
    "#         return proposal_classes\n",
    "\n",
    "\n",
    "# detection = Detection()#.cuda()\n",
    "# fast_feature = torch.randn(320, 128, 1, 32)\n",
    "# slow_feature = torch.randn(320, 256, 1, 32)\n",
    "# y = detection(fast_feature, slow_feature)\n",
    "# y.shape\n",
    "\n",
    "class PoolConcatPathway(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pool,\n",
    "        dim: int = 1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        \n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        output = []\n",
    "        for ind in range(len(x)):\n",
    "            if x[ind] is not None:\n",
    "                if self.pool is not None and self.pool[ind] is not None:\n",
    "                    x[ind] = self.pool[ind](x[ind])\n",
    "                # print(99, x[ind].shape)\n",
    "                output.append(x[ind])\n",
    "        return torch.cat(output, 1)\n",
    "\n",
    "\n",
    "_num_pathway=2\n",
    "head_pool_kernel_sizes = ((111, 1), (2, 1))\n",
    "pool_model = [\n",
    "    nn.AvgPool2d(\n",
    "        kernel_size=head_pool_kernel_sizes[idx],\n",
    "        stride=(1, 1),\n",
    "        padding=(0, 0),\n",
    "    )\n",
    "    for idx in range(_num_pathway)\n",
    "]\n",
    "poolconcat = PoolConcatPathway(pool_model)\n",
    "fast_feature = torch.randn(320, 64, 125, 1)\n",
    "slow_feature = torch.randn(320, 1024, 16, 1)\n",
    "# fast_feature = torch.randn(320, 64, 32, 56)\n",
    "# slow_feature = torch.randn(320, 1024, 4, 56)\n",
    "\n",
    "y = poolconcat([fast_feature, slow_feature])\n",
    "print(y.shape)\n",
    "\n",
    "# torch.Size([320, 256, 32, 7])\n",
    "\n",
    "    \n",
    "class ResNetBasicHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dropout_rate=0.5\n",
    "        in_features=1088\n",
    "        out_features=40\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.proj = nn.Linear(in_features, out_features)\n",
    "        self.outputpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "    \n",
    "        x = x.permute((0, 2, 3, 1))\n",
    "        x = self.proj(x)\n",
    "        x = x.permute((0, 3, 1, 2))\n",
    "        \n",
    "        x = self.outputpool(x)\n",
    "        x = x.squeeze()\n",
    "        return x\n",
    "    \n",
    "pooled = torch.randn(320, 1088, 15, 1)\n",
    "head = ResNetBasicHead()\n",
    "out = head(pooled)\n",
    "print(out.shape)\n",
    "\n",
    "# detection = Detection()\n",
    "# fast_feature = torch.randn(320, 64, 125, 1)\n",
    "# slow_feature = torch.randn(320, 1024, 16, 1)\n",
    "# y = detection(fast_feature, slow_feature)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 40])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class Model(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.backbone = SlowFast()\n",
    "#         self.detection = Detection()\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         fast_feature, slow_feature = self.backbone(input)\n",
    "#         # print(99, fast_feature.shape, slow_feature.shape)\n",
    "#         y = self.detection(fast_feature, slow_feature)\n",
    "#         return y\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = SlowFast()\n",
    "        # self.detection = Detection()\n",
    "        \n",
    "        _num_pathway=2\n",
    "        head_pool_kernel_sizes = ((111, 1), (2, 1))\n",
    "        pool_model = [\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=head_pool_kernel_sizes[idx],\n",
    "                stride=(1, 1),\n",
    "                padding=(0, 0),\n",
    "            )\n",
    "            for idx in range(_num_pathway)\n",
    "        ]\n",
    "        self.poolconcat = PoolConcatPathway(pool_model)\n",
    "        self.head = ResNetBasicHead()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        fast_feature, slow_feature = self.backbone(input)\n",
    "        # print(99, fast_feature.shape, slow_feature.shape)\n",
    "        # y = self.detection(fast_feature, slow_feature)\n",
    "        \n",
    "        y = self.poolconcat([fast_feature, slow_feature])\n",
    "        out = self.head(y)\n",
    "        return out\n",
    "    \n",
    "model = Model()\n",
    "y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_subject_kfold(data, config, test_subject_id, kfold_k=0):\n",
    "    \n",
    "    ## init data\n",
    "    \n",
    "    # train_dataset, val_dataset, test_dataset = leave_one_subject_out(data, test_subject_id=test_subject_id, kfold_k=kfold_k)\n",
    "    train_dataset, val_dataset, test_dataset = data.get_train_val_test_dataset(test_subject_id=test_subject_id, kfold_k=kfold_k)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.training.batchsize, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.training.batchsize, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.training.batchsize, shuffle=False)\n",
    "\n",
    "    ## init model\n",
    "\n",
    "    eegnet = Model()\n",
    "\n",
    "    model = LightningModelClassifier(\n",
    "        optimizer=config.model.optimizer,\n",
    "        scheduler=config.model.scheduler,\n",
    "        optimizer_learning_rate=config.training.learning_rate,\n",
    "        scheduler_warmup_epochs=config.training.num_warmup_epochs,\n",
    "    )\n",
    "    \n",
    "    model.build_model(model=eegnet)\n",
    "\n",
    "    ## train\n",
    "\n",
    "    sub_dir = \"sub\"+ str(test_subject_id) +\"_k\"+ str(kfold_k)\n",
    "    logger_tb = TensorBoardLogger(save_dir=\"tensorboard_logs\", name=config.run_name, sub_dir=sub_dir)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "    trainer = Trainer(max_epochs=config.training.num_epochs, gpus=config.training.gpus, logger=logger_tb, progress_bar_refresh_rate=0, weights_summary=None, callbacks=[lr_monitor])\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    ## test\n",
    "    \n",
    "    result = trainer.test(dataloaders=test_loader, verbose=False)\n",
    "    test_acc = result[0]['test_acc_epoch']\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running test_subject_id: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 1234\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_subject_id': 33, 'acc': [0.02916666679084301]}\n",
      "\n",
      "mean all 0.02916666679084301\n"
     ]
    }
   ],
   "source": [
    "main_logger.write_to_log(\"Begin\", break_line=True)\n",
    "\n",
    "test_results_acc = {}\n",
    "means = []\n",
    "\n",
    "def k_fold_train_test_all_subjects():\n",
    "    \n",
    "    for test_subject_id in config.testing.test_subject_ids:\n",
    "        print()\n",
    "        print(\"running test_subject_id:\", test_subject_id)\n",
    "        \n",
    "        if test_subject_id not in test_results_acc:\n",
    "            test_results_acc[test_subject_id] = []\n",
    "        \n",
    "        test_acc = train_test_subject_kfold(data, config, test_subject_id, kfold_k=0)\n",
    "            \n",
    "        test_results_acc[test_subject_id].append(test_acc)\n",
    "        means.append(test_acc)\n",
    "        \n",
    "        this_result = {\n",
    "            \"test_subject_id\": test_subject_id,\n",
    "            \"acc\": test_results_acc[test_subject_id],\n",
    "        }        \n",
    "        print(this_result)\n",
    "        main_logger.write_to_log(this_result)\n",
    "\n",
    "        \n",
    "k_fold_train_test_all_subjects()\n",
    "\n",
    "mean_acc = np.mean(means)\n",
    "print()\n",
    "print(\"mean all\", mean_acc)\n",
    "main_logger.write_to_log(\"Mean acc: \"+str(mean_acc), break_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
