{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jinglescode/python-signal-processing/blob/main/tutorials/Task-Related%20Component%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QR5KHrc-0eC"
   },
   "source": [
    "# Task-Related Component Analysis\n",
    "\n",
    "Task-related component analysis (TRCA) is a classifier, originally for steady-state visual evoked potentials (SSVEPs) detection.\n",
    "\n",
    "Taken from the [paper](http://ieeexplore.ieee.org/document/7904641/) abstract:\n",
    "> Task-related component analysis (TRCA), which can enhance reproducibility of SSVEPs across multiple trials, was employed to improve the signal-to-noise ratio (SNR) of SSVEP signals by removing background electroencephalographic (EEG) activities. An ensemble method was further developed to integrate TRCA filters corresponding to multiple stimulation frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jn9DFi6-0kr",
    "outputId": "3a1db3f0-5f74-4181-83b3-753b69a9eec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'python-signal-processing'...\n",
      "remote: Enumerating objects: 198, done.\u001b[K\n",
      "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
      "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
      "remote: Total 198 (delta 111), reused 118 (delta 50), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (198/198), 22.08 MiB | 36.88 MiB/s, done.\n",
      "Resolving deltas: 100% (111/111), done.\n",
      "/content/python-signal-processing\n"
     ]
    }
   ],
   "source": [
    "#@title \n",
    "!git clone https://github.com/jinglescode/python-signal-processing.git\n",
    "%cd python-signal-processing\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f2h9lGUY-1n4"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from splearn.cross_decomposition.trca import TRCA # https://github.com/jinglescode/python-signal-processing/blob/main/splearn/cross_decomposition/trca.py\n",
    "from splearn.data.sample_ssvep import SampleSSVEPData # https://github.com/jinglescode/python-signal-processing/blob/main/splearn/data/sample_ssvep.py\n",
    "from splearn.cross_validate.leave_one_out import leave_one_block_evaluation # https://github.com/jinglescode/python-signal-processing/blob/main/splearn/cross_validate.leave_one_out.py\n",
    "from splearn.cross_decomposition.cca import CCA # https://github.com/jinglescode/python-signal-processing/blob/main/splearn/cross_decomposition/cca.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noE6FEDCIP_8"
   },
   "source": [
    "## Load data\n",
    "\n",
    "In this tutorial, we load a 40-target steady-state visual evoked potentials (SSVEP) dataset recorded from a single subject. It contains 6 blocks, each block consists of 40 trials, where each trial is a target. The electroencephalogram (EEG) signals has 9 channels and 1250 sampling points.\n",
    "\n",
    "Read more about this dataset: https://www.pnas.org/content/early/2015/10/14/1508080112.abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UisorSY-1qk",
    "outputId": "f025c66f-3ecb-4cc1-ae92-a3c4c3719671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg.shape: (6, 40, 9, 1250)\n",
      "labels.shape: (6, 40)\n"
     ]
    }
   ],
   "source": [
    "data = SampleSSVEPData()\n",
    "eeg = data.get_data()\n",
    "labels = data.get_targets()\n",
    "print(\"eeg.shape:\", eeg.shape)\n",
    "print(\"labels.shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XcPql_8H2d4"
   },
   "source": [
    "## Leave-One-Block-Out cross-validation\n",
    "\n",
    "We use the Leave-One-Block-Out cross-validation approach to determine TRCA's classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUOpOyBU_CcF",
    "outputId": "b9a299b4-d0ab-4045-af23-0025d54be6c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block: 1 | Train acc: 100.00% | Test acc: 97.50%\n",
      "Block: 2 | Train acc: 100.00% | Test acc: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ad1360b3b7d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrca_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTRCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_accuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleave_one_block_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrca_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meeg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\workspace\\github\\python-signal-processing\\splearn\\cross_validate\\leave_one_out.py\u001b[0m in \u001b[0;36mleave_one_block_evaluation\u001b[1;34m(classifier, X, Y)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mblock_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mtest_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\github\\python-signal-processing\\splearn\\cross_validate\\leave_one_out.py\u001b[0m in \u001b[0;36mblock_evaluation\u001b[1;34m(classifier, X, Y, block_i)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\github\\python-signal-processing\\splearn\\cross_decomposition\\trca.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m                         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfb_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                         \u001b[1;31m# Follows corrcoef MATLAB function implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                         \u001b[0mr_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfb_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trca_classifier = TRCA(sampling_rate=data.sampling_rate)\n",
    "test_accuracies = leave_one_block_evaluation(classifier=trca_classifier, X=eeg, Y=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ccn3ee-4OZO"
   },
   "source": [
    "### Comparing to CCA\n",
    "Let's also test the classification performance with [CCA](https://colab.research.google.com/github/jinglescode/python-signal-processing/blob/main/tutorials/Canonical%20Correlation%20Analysis.ipynb) and compare the accuracy performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DrOzs9H4HD-",
    "outputId": "a64c333e-f36b-4f5e-9ac4-6b65243803f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block: 1 | Test acc: 100.00%\n",
      "Block: 2 | Test acc: 100.00%\n",
      "Block: 3 | Test acc: 100.00%\n",
      "Block: 4 | Test acc: 100.00%\n",
      "Block: 5 | Test acc: 100.00%\n",
      "Block: 6 | Test acc: 100.00%\n",
      "Mean test accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "cca = CCA(\n",
    "    sampling_rate=data.sampling_rate, \n",
    "    target_frequencies=data.get_stimulus_frequencies(), \n",
    "    signal_size=eeg.shape[3], \n",
    "    num_harmonics=1\n",
    ")\n",
    "\n",
    "test_accuracies = leave_one_block_evaluation(classifier=cca, X=eeg, Y=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VF6_inPQIYH"
   },
   "source": [
    "Comparing the `mean test accuracy`, we can't see the difference in the classification performance between TRCA and CCA. We will use another dataset below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggjguM6YDOke"
   },
   "source": [
    "## Using `.fit` and `.predict`\n",
    "\n",
    "In this example, we select the first 2 blocks for training and the remaining 4 blocks for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MsLQSLggDOrY",
    "outputId": "be4f5c33-048d-4dd7-a8ce-cccc25ffed64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (80, 9, 1250) (80,)\n",
      "Block: 3 | accuracy: 100.00%\n",
      "Block: 4 | accuracy: 100.00%\n",
      "Block: 5 | accuracy: 97.50%\n",
      "Block: 6 | accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "trca_classifier = TRCA(sampling_rate=data.sampling_rate)\n",
    "\n",
    "x_train = eeg[0:2]\n",
    "y_train = labels[0:2]\n",
    "\n",
    "blocks, targets, channels, samples = x_train.shape\n",
    "x_train = x_train.reshape((blocks-1*targets, channels, samples))\n",
    "y_train = y_train.reshape((blocks-1*targets))\n",
    "\n",
    "print(\"Train shape:\", x_train.shape, y_train.shape)\n",
    "trca_classifier.fit(x_train, y_train)\n",
    "\n",
    "for block_i in range(2, 6):\n",
    "\n",
    "    test_x = eeg[block_i]\n",
    "    test_y = labels[block_i]\n",
    "\n",
    "    # Shuffle the test set\n",
    "    arrangement = np.arange(40)\n",
    "    np.random.shuffle(arrangement)\n",
    "    test_x = test_x[arrangement, :,:]\n",
    "    test_y = test_y[arrangement]\n",
    "\n",
    "    # Preduct\n",
    "    pred = trca_classifier.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred)\n",
    "\n",
    "    print(f'Block: {block_i+1} | accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_ItEaQy3ewU"
   },
   "source": [
    "## Another dataset, HS-SSVEP\n",
    "\n",
    "As we can't see the difference in classification performance with the previous data, in this example we will evaluate with a single subject data taken from the [Tsinghua SSVEP benchmark dataset](https://ieeexplore.ieee.org/document/7740878).\n",
    "\n",
    "In the following code blocks, we will download and prepare the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9z1jdUGw3e4g",
    "outputId": "52a0c191-c343-43fd-a8ad-a9b84d6a4892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-18 13:12:13--  ftp://anonymous@sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat\n",
      "           => ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/.listing’\n",
      "Resolving sccn.ucsd.edu (sccn.ucsd.edu)... 169.228.38.2\n",
      "Connecting to sccn.ucsd.edu (sccn.ucsd.edu)|169.228.38.2|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /pub/ssvep_benchmark_dataset ... done.\n",
      "==> PASV ... done.    ==> LIST ... done.\n",
      "\n",
      "sccn.ucsd.edu/pub/s     [ <=>                ]   2.78K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-08-18 13:12:14 (261 MB/s) - ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/.listing’ saved [2850]\n",
      "\n",
      "Removed ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/.listing’.\n",
      "--2021-08-18 13:12:14--  ftp://anonymous@sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat\n",
      "           => ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat’\n",
      "==> CWD not required.\n",
      "==> PASV ... done.    ==> RETR S33.mat ... done.\n",
      "Length: 106223727 (101M)\n",
      "\n",
      "sccn.ucsd.edu/pub/s 100%[===================>] 101.30M  34.5MB/s    in 2.9s    \n",
      "\n",
      "2021-08-18 13:12:17 (34.5 MB/s) - ‘sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat’ saved [106223727]\n",
      "\n",
      "FINISHED --2021-08-18 13:12:17--\n",
      "Total wall clock time: 4.1s\n",
      "Downloaded: 1 files, 101M in 2.9s (34.5 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget -r --no-parent ftp://anonymous@sccn.ucsd.edu/pub/ssvep_benchmark_dataset/S33.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkUyEd_l3lV6",
    "outputId": "a2c1ccaa-358c-46d3-fffe-7d5c1cb0a011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (6, 40, 9, 250)\n",
      "Label shape: (200,) (40,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# select channels\n",
    "ch_names = ['FP1','FPZ','FP2','AF3','AF4','F7','F5','F3','F1','FZ','F2','F4','F6','F8','FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8','T7','C5','C3','C1','Cz','C2','C4','C6','T8','M1','TP7','CP5','CP3','CP1','CPZ','CP2','CP4','CP6','TP8','M2','P7','P5','P3','P1','PZ','P2','P4','P6','P8','PO7','PO5','PO3','POz','PO4','PO6','PO8','CB1','O1','Oz','O2','CB2']\n",
    "ch_index = [47,53,54,55,56,57,60,61,62]\n",
    "\n",
    "sampling_rate = 250\n",
    "\n",
    "folder = 'sccn.ucsd.edu/pub/ssvep_benchmark_dataset'\n",
    "data = loadmat(f\"{folder}/S33.mat\")\n",
    "eeg = data['data']\n",
    "eeg = eeg.transpose((3, 2, 0, 1))\n",
    "eeg = eeg[:,  :, ch_index, 250:500]\n",
    "print(\"Data shape:\", eeg.shape)\n",
    "\n",
    "blocks, targets, channels, samples = eeg.shape\n",
    "y_train = np.tile(np.arange(0, targets), (1, blocks-1)).squeeze()\n",
    "y_test = np.arange(0, targets)\n",
    "print(\"Label shape:\", y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPTZLMIGTU_E"
   },
   "source": [
    "## Classification with TRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hchO2WOS7DDh",
    "outputId": "98d7404f-db78-45b6-c83d-ae81f50c9bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block: 1 | Train acc: 100.00% | Test acc: 70.00%\n",
      "Block: 2 | Train acc: 100.00% | Test acc: 47.50%\n",
      "Block: 3 | Train acc: 100.00% | Test acc: 67.50%\n",
      "Block: 4 | Train acc: 100.00% | Test acc: 47.50%\n",
      "Block: 5 | Train acc: 100.00% | Test acc: 70.00%\n",
      "Block: 6 | Train acc: 100.00% | Test acc: 62.50%\n",
      "Mean test accuracy: 60.8%\n"
     ]
    }
   ],
   "source": [
    "trca_classifier = TRCA(sampling_rate=sampling_rate)\n",
    "test_accuracies = leave_one_block_evaluation(classifier=trca_classifier, X=eeg, Y=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhHEECitTaMM"
   },
   "source": [
    "### Comparing to CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PBJCxXaz6jpa",
    "outputId": "c5d097a1-5a26-47a6-fad7-3d2da7943cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block: 1 | Train acc: 20.50% | Test acc: 35.00%\n",
      "Block: 2 | Train acc: 26.00% | Test acc: 7.50%\n",
      "Block: 3 | Train acc: 22.00% | Test acc: 27.50%\n",
      "Block: 4 | Train acc: 23.50% | Test acc: 20.00%\n",
      "Block: 5 | Train acc: 23.50% | Test acc: 20.00%\n",
      "Block: 6 | Train acc: 22.00% | Test acc: 27.50%\n",
      "Mean test accuracy: 22.900000000000002%\n"
     ]
    }
   ],
   "source": [
    "stimulus_frequencies = np.array([8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,8.2,9.2,10.2,11.2,12.2,13.2,14.2,15.2,8.4,9.4,10.4,11.4,12.4,13.4,14.4,15.4,8.6,9.6,10.6,11.6,12.6,13.6,14.6,15.6,8.8,9.8,10.8,11.8,12.8,13.8,14.8,15.8])\n",
    "\n",
    "cca = CCA(\n",
    "    sampling_rate=sampling_rate, \n",
    "    target_frequencies=stimulus_frequencies,\n",
    "    signal_size=eeg.shape[3], \n",
    "    num_harmonics=2\n",
    ")\n",
    "\n",
    "test_accuracies = leave_one_block_evaluation(classifier=cca, X=eeg, Y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRCA utils.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import filtfilt, cheb1ord, cheby1\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def round_half_up(num, decimals=0):\n",
    "    \"\"\"Round half up round the last decimal of the number.\n",
    "    The rules are:\n",
    "    from 0 to 4 rounds down\n",
    "    from 5 to 9 rounds up\n",
    "    Parameters\n",
    "    ----------\n",
    "    num : float\n",
    "        Number to round\n",
    "    decimals : number of decimals\n",
    "    Returns\n",
    "    -------\n",
    "    num rounded\n",
    "    \"\"\"\n",
    "    multiplier = 10 ** decimals\n",
    "    return int(np.floor(num * multiplier + 0.5) / multiplier)\n",
    "\n",
    "\n",
    "def normfit(data, ci=0.95):\n",
    "    \"\"\"Compute the mean, std and confidence interval for them.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array, shape=()\n",
    "        Input data.\n",
    "    ci : float\n",
    "        Confidence interval (default=0.95).\n",
    "    Returns\n",
    "    -------\n",
    "    m : float\n",
    "        Mean.\n",
    "    sigma : float\n",
    "        Standard deviation\n",
    "    [m - h, m + h] : list\n",
    "        Confidence interval of the mean.\n",
    "    [sigmaCI_lower, sigmaCI_upper] : list\n",
    "        Confidence interval of the std.\n",
    "    \"\"\"\n",
    "    arr = 1.0 * np.array(data)\n",
    "    num = len(arr)\n",
    "    avg, std_err = np.mean(arr), stats.sem(arr)\n",
    "    h_int = std_err * stats.t.ppf((1 + ci) / 2., num - 1)\n",
    "    var = np.var(data, ddof=1)\n",
    "    var_ci_upper = var * (num - 1) / stats.chi2.ppf((1 - ci) / 2, num - 1)\n",
    "    var_ci_lower = var * (num - 1) / stats.chi2.ppf(1 - (1 - ci) / 2, num - 1)\n",
    "    sigma = np.sqrt(var)\n",
    "    sigma_ci_lower = np.sqrt(var_ci_lower)\n",
    "    sigma_ci_upper = np.sqrt(var_ci_upper)\n",
    "\n",
    "    return avg, sigma, [avg - h_int, avg +\n",
    "                        h_int], [sigma_ci_lower, sigma_ci_upper]\n",
    "\n",
    "\n",
    "def itr(n, p, t):\n",
    "    \"\"\"Compute information transfer rate (ITR).\n",
    "    Definition in [1]_.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of targets.\n",
    "    p : float\n",
    "        Target identification accuracy (0 <= p <= 1).\n",
    "    t : float\n",
    "        Average time for a selection (s).\n",
    "    Returns\n",
    "    -------\n",
    "    itr : float\n",
    "        Information transfer rate [bits/min]\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Cheng, X. Gao, S. Gao, and D. Xu,\n",
    "        \"Design and Implementation of a Brain-Computer Interface With High\n",
    "        Transfer Rates\", IEEE Trans. Biomed. Eng. 49, 1181-1186, 2002.\n",
    "    \"\"\"\n",
    "    itr = 0\n",
    "\n",
    "    if (p < 0 or 1 < p):\n",
    "        raise ValueError('Accuracy need to be between 0 and 1.')\n",
    "    elif (p < 1 / n):\n",
    "        itr = 0\n",
    "        raise ValueError('ITR might be incorrect because accuracy < chance')\n",
    "    elif (p == 1):\n",
    "        itr = np.log2(n) * 60 / t\n",
    "    else:\n",
    "        itr = (np.log2(n) + p * np.log2(p) + (1 - p) *\n",
    "               np.log2((1 - p) / (n - 1))) * 60 / t\n",
    "\n",
    "    return itr\n",
    "\n",
    "\n",
    "def bandpass(eeg, sfreq, Wp, Ws):\n",
    "    \"\"\"Filter bank design for decomposing EEG data into sub-band components.\n",
    "    Parameters\n",
    "    ----------\n",
    "    eeg : np.array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "    sfreq : int\n",
    "        Sampling frequency of the data.\n",
    "    Wp : 2-tuple\n",
    "        Passband for Chebyshev filter.\n",
    "    Ws : 2-tuple\n",
    "        Stopband for Chebyshev filter.\n",
    "    Returns\n",
    "    -------\n",
    "    y: np.array, shape=(n_trials, n_chans, n_samples)\n",
    "        Sub-band components decomposed by a filter bank.\n",
    "    See Also\n",
    "    --------\n",
    "    scipy.signal.cheb1ord :\n",
    "        Chebyshev type I filter order selection.\n",
    "    \"\"\"\n",
    "    # Chebyshev type I filter order selection.\n",
    "    N, Wn = cheb1ord(Wp, Ws, 3, 40, fs=sfreq)\n",
    "\n",
    "    # Chebyshev type I filter design\n",
    "    B, A = cheby1(N, 0.5, Wn, btype=\"bandpass\", fs=sfreq)\n",
    "\n",
    "    # the arguments 'axis=0, padtype='odd', padlen=3*(max(len(B),len(A))-1)'\n",
    "    # correspond to Matlab filtfilt : https://dsp.stackexchange.com/a/47945\n",
    "    y = filtfilt(B, A, eeg, axis=0, padtype='odd',\n",
    "                 padlen=3 * (max(len(B), len(A)) - 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "def schaefer_strimmer_cov(X):\n",
    "    r\"\"\"Schaefer-Strimmer covariance estimator.\n",
    "    Shrinkage estimator described in [1]_:\n",
    "    .. math:: \\hat{\\Sigma} = (1 - \\gamma)\\Sigma_{scm} + \\gamma T\n",
    "    where :math:`T` is the diagonal target matrix:\n",
    "    .. math:: T_{i,j} = \\{ \\Sigma_{scm}^{ii} \\text{if} i = j,\n",
    "         0 \\text{otherwise} \\}\n",
    "    Note that the optimal :math:`\\gamma` is estimated by the authors' method.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array, shape=(n_chans, n_samples)\n",
    "        Signal matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    cov: array, shape=(n_chans, n_chans)\n",
    "        Schaefer-Strimmer shrinkage covariance matrix.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Schafer, J., and K. Strimmer. 2005. A shrinkage approach to\n",
    "       large-scale covariance estimation and implications for functional\n",
    "       genomics. Statist. Appl. Genet. Mol. Biol. 4:32.\n",
    "    \"\"\"\n",
    "    ns = X.shape[1]\n",
    "    C_scm = np.cov(X, ddof=0)\n",
    "    X_c = X - np.tile(X.mean(axis=1), [ns, 1]).T\n",
    "\n",
    "    # Compute optimal gamma, the weigthing between SCM and srinkage estimator\n",
    "    R = ns / (ns - 1.0) * np.corrcoef(X)\n",
    "    var_R = (X_c ** 2).dot((X_c ** 2).T) - 2 * C_scm * X_c.dot(X_c.T)\n",
    "    var_R += ns * C_scm ** 2\n",
    "\n",
    "    var_R = ns / ((ns - 1) ** 3 * np.outer(X.var(1), X.var(1))) * var_R\n",
    "    R -= np.diag(np.diag(R))\n",
    "    var_R -= np.diag(np.diag(var_R))\n",
    "    gamma = max(0, min(1, var_R.sum() / (R ** 2).sum()))\n",
    "\n",
    "    cov = (1. - gamma) * (ns / (ns - 1.)) * C_scm\n",
    "    cov += gamma * (ns / (ns - 1.)) * np.diag(np.diag(C_scm))\n",
    "\n",
    "    return cov\n",
    "\n",
    "\n",
    "def _check_data(X):\n",
    "    \"\"\"Check data is numpy array and has the proper dimensions.\"\"\"\n",
    "    if not isinstance(X, (np.ndarray, list)):\n",
    "        raise AttributeError('data should be a list or a numpy array')\n",
    "\n",
    "    dtype = np.complex128 if np.any(np.iscomplex(X)) else np.float64\n",
    "    X = np.asanyarray(X, dtype=dtype)\n",
    "    if X.ndim > 3:\n",
    "        raise ValueError('Data must be 3D at most')\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def theshapeof(X):\n",
    "    \"\"\"Return the shape of X.\"\"\"\n",
    "    X = _check_data(X)\n",
    "    # if not isinstance(X, np.ndarray):\n",
    "    #     raise AttributeError('X must be a numpy array')\n",
    "\n",
    "    if X.ndim == 3:\n",
    "        return X.shape[0], X.shape[1], X.shape[2]\n",
    "    elif X.ndim == 2:\n",
    "        return X.shape[0], X.shape[1], 1\n",
    "    elif X.ndim == 1:\n",
    "        return X.shape[0], 1, 1\n",
    "    else:\n",
    "        raise ValueError(\"Array contains more than 3 dimensions\")\n",
    "\n",
    "        \n",
    "###################\n",
    "\n",
    "\n",
    "\"\"\"Task-Related Component Analysis.\"\"\"\n",
    "# Authors: Giuseppe Ferraro <giuseppe.ferraro@isae-supaero.fr>\n",
    "#          Ludovic Darmet <ludovic.darmet@isae-supaero.fr>\n",
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "from pyriemann.estimation import Covariances\n",
    "\n",
    "\n",
    "class TRCA:\n",
    "    \"\"\"Task-Related Component Analysis (TRCA).\n",
    "    Parameters\n",
    "    ----------\n",
    "    sfreq : float\n",
    "        Sampling rate.\n",
    "    filterbank : list[[2-tuple, 2-tuple]]\n",
    "        Filterbank frequencies. Each list element is itself a list of passband\n",
    "        `Wp` and stopband `Ws` edges frequencies `[Wp, Ws]`. For example, this\n",
    "        creates 3 bands, starting at 6, 14, and 22 hz respectively::\n",
    "            [[(6, 90), (4, 100)],\n",
    "             [(14, 90), (10, 100)],\n",
    "             [(22, 90), (16, 100)]]\n",
    "        See :func:`scipy.signal.cheb1ord()` for more information on how to\n",
    "        specify the `Wp` and `Ws`.\n",
    "    ensemble : bool\n",
    "        If True, perform the ensemble TRCA analysis (default=False).\n",
    "    method : str in {'original'| 'riemann'}\n",
    "        Use original implementation from [1]_ or a variation that uses\n",
    "        regularization and the geodesic mean [2]_.\n",
    "    regularization : str in {'schaefer' | 'lwf' | 'oas' | 'scm'}\n",
    "        Regularization estimator used for covariance estimation with the\n",
    "        `riemann` method. Consider 'schaefer', 'lwf', 'oas'. 'scm' does not add\n",
    "        regularization and is almost equivalent to the original implementation.\n",
    "    Attributes\n",
    "    ----------\n",
    "    traindata : array, shape=(n_bands, n_chans, n_trials)\n",
    "        Reference (training) data decomposed into sub-band components by the\n",
    "        filter bank analysis.\n",
    "    y_train : array, shape=(n_trials)\n",
    "        Labels associated with the train data.\n",
    "    coef_ : array, shape=(n_chans, n_chans)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "    classes : list\n",
    "        Classes.\n",
    "    n_bands : int\n",
    "        Number of sub-bands.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
    "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
    "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
    "       472-476). IEEE.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sfreq, filterbank, ensemble=False, method='original',\n",
    "                 estimator='scm'):\n",
    "        self.sfreq = sfreq\n",
    "        self.ensemble = ensemble\n",
    "        self.filterbank = filterbank\n",
    "        self.n_bands = len(self.filterbank)\n",
    "        self.coef_ = None\n",
    "        self.method = method\n",
    "        if estimator == 'schaefer':\n",
    "            self.estimator = schaefer_strimmer_cov\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "            \n",
    "        self.can_train = True\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Training stage of the TRCA-based SSVEP detection.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "            Training EEG data.\n",
    "        y : array, shape=(trials,)\n",
    "            True label corresponding to each trial of the data array.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = np.transpose(X, (2,1,0))\n",
    "        \n",
    "        n_samples, n_chans, _ = theshapeof(X)\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        trains = np.zeros((len(classes), self.n_bands, n_samples, n_chans))\n",
    "\n",
    "        W = np.zeros((self.n_bands, len(classes), n_chans))\n",
    "\n",
    "        for class_i in classes:\n",
    "            # Select data with a specific label\n",
    "            eeg_tmp = X[..., y == class_i]\n",
    "            for fb_i in range(self.n_bands):\n",
    "                # Filter the signal with fb_i\n",
    "                eeg_tmp = bandpass(eeg_tmp, self.sfreq,\n",
    "                                   Wp=self.filterbank[fb_i][0],\n",
    "                                   Ws=self.filterbank[fb_i][1])\n",
    "                if (eeg_tmp.ndim == 3):\n",
    "                    # Compute mean of the signal across trials\n",
    "                    trains[class_i, fb_i] = np.mean(eeg_tmp, -1)\n",
    "                else:\n",
    "                    trains[class_i, fb_i] = eeg_tmp\n",
    "                # Find the spatial filter for the corresponding filtered signal\n",
    "                # and label\n",
    "                if self.method == 'original':\n",
    "                    w_best = trca(eeg_tmp)\n",
    "                elif self.method == 'riemann':\n",
    "                    w_best = trca_regul(eeg_tmp, self.estimator)\n",
    "                else:\n",
    "                    raise ValueError('Invalid `method` option.')\n",
    "\n",
    "                W[fb_i, class_i, :] = w_best  # Store the spatial filter\n",
    "\n",
    "        self.trains = trains\n",
    "        self.coef_ = W\n",
    "        self.classes = classes\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Test phase of the TRCA-based SSVEP detection.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array, shape=(n_samples, n_chans[, n_trials])\n",
    "            Test data.\n",
    "        model: dict\n",
    "            Fitted model to be used in testing phase.\n",
    "        Returns\n",
    "        -------\n",
    "        pred: np.array, shape (trials)\n",
    "            The target estimated by the method.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = np.transpose(X, (2,1,0))\n",
    "        \n",
    "        if self.coef_ is None:\n",
    "            raise RuntimeError('TRCA is not fitted')\n",
    "\n",
    "        # Alpha coefficients for the fusion of filterbank analysis\n",
    "        fb_coefs = [(x + 1)**(-1.25) + 0.25 for x in range(self.n_bands)]\n",
    "        _, _, n_trials = theshapeof(X)\n",
    "\n",
    "        r = np.zeros((self.n_bands, len(self.classes)))\n",
    "        pred = np.zeros((n_trials), 'int')  # To store predictions\n",
    "\n",
    "        for trial in range(n_trials):\n",
    "            test_tmp = X[..., trial]  # pick a trial to be analysed\n",
    "            for fb_i in range(self.n_bands):\n",
    "\n",
    "                # filterbank on testdata\n",
    "                testdata = bandpass(test_tmp, self.sfreq,\n",
    "                                    Wp=self.filterbank[fb_i][0],\n",
    "                                    Ws=self.filterbank[fb_i][1])\n",
    "\n",
    "                for class_i in self.classes:\n",
    "                    # Retrieve reference signal for class i\n",
    "                    # (shape: n_chans, n_samples)\n",
    "                    traindata = np.squeeze(self.trains[class_i, fb_i])\n",
    "                    if self.ensemble:\n",
    "                        # shape = (n_chans, n_classes)\n",
    "                        w = np.squeeze(self.coef_[fb_i]).T\n",
    "                    else:\n",
    "                        # shape = (n_chans)\n",
    "                        w = np.squeeze(self.coef_[fb_i, class_i])\n",
    "\n",
    "                    # Compute 2D correlation of spatially filtered test data\n",
    "                    # with ref\n",
    "                    r_tmp = np.corrcoef((testdata @ w).flatten(),\n",
    "                                        (traindata @ w).flatten())\n",
    "                    r[fb_i, class_i] = r_tmp[0, 1]\n",
    "\n",
    "            rho = np.dot(fb_coefs, r)  # fusion for the filterbank analysis\n",
    "\n",
    "            tau = np.argmax(rho)  # retrieving index of the max\n",
    "            pred[trial] = int(tau)\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "def trca(X):\n",
    "    \"\"\"Task-related component analysis.\n",
    "    This function implements the method described in [1]_.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "    Returns\n",
    "    -------\n",
    "    W : array, shape=(n_chans,)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    \"\"\"\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Covariance\n",
    "    Q = UX @ UX.T\n",
    "\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    S = np.zeros((n_chans, n_chans))\n",
    "    for trial_i in range(n_trials - 1):\n",
    "        x1 = np.squeeze(X[..., trial_i])\n",
    "\n",
    "        # Mean centering for the selected trial\n",
    "        x1 -= np.mean(x1, 0)\n",
    "\n",
    "        # Select a second trial that is different\n",
    "        for trial_j in range(trial_i + 1, n_trials):\n",
    "            x2 = np.squeeze(X[..., trial_j])\n",
    "\n",
    "            # Mean centering for the selected trial\n",
    "            x2 -= np.mean(x2, 0)\n",
    "\n",
    "            # Compute empirical covariance between the two selected trials and\n",
    "            # sum it\n",
    "            S = S + x1.T @ x2 + x2.T @ x1\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best\n",
    "\n",
    "\n",
    "def trca_regul(X, method):\n",
    "    \"\"\"Task-related component analysis.\n",
    "    This function implements a variation of the method described in [1]_. It is\n",
    "    inspired by a riemannian geometry approach to CSP [2]_. It adds\n",
    "    regularization to the covariance matrices and uses the riemannian mean for\n",
    "    the inter-trial covariance matrix `S`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "    Returns\n",
    "    -------\n",
    "    W : array, shape=(n_chans,)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
    "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
    "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
    "       472-476). IEEE.\n",
    "    \"\"\"\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Compute empirical variance of all data (to be bounded)\n",
    "    cov = Covariances(estimator=method).fit_transform(UX[np.newaxis, ...])\n",
    "    Q = np.squeeze(cov)\n",
    "\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Intertrial correlation computation\n",
    "    data = np.concatenate((X, X), axis=1)\n",
    "\n",
    "    # Swapaxes to fit pyriemann Covariances\n",
    "    data = np.swapaxes(data, 0, 2)\n",
    "    cov = Covariances(estimator=method).fit_transform(data)\n",
    "\n",
    "    # Keep only inter-trial\n",
    "    S = cov[:, :n_chans, n_chans:] + cov[:, n_chans:, :n_chans]\n",
    "\n",
    "    # If the number of samples is too big, we compute an approximate of\n",
    "    # riemannian mean to speed up the computation\n",
    "    if n_trials < 30:\n",
    "        S = mean_covariance(S, metric='riemann')\n",
    "    else:\n",
    "        S = mean_covariance(S, metric='logeuclid')\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block: 1 | Train acc: 100.00% | Test acc: 97.50%\n",
      "Block: 2 | Train acc: 100.00% | Test acc: 100.00%\n",
      "Block: 3 | Train acc: 100.00% | Test acc: 100.00%\n",
      "Block: 4 | Train acc: 100.00% | Test acc: 100.00%\n",
      "Block: 5 | Train acc: 100.00% | Test acc: 97.50%\n",
      "Block: 6 | Train acc: 100.00% | Test acc: 100.00%\n",
      "Mean test accuracy: 99.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.975, 1.0, 1.0, 1.0, 0.975, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfreq = data.sampling_rate\n",
    "filterbank = [[(6, 90), (4, 100)],  # passband, stopband freqs [(Wp), (Ws)]\n",
    "              [(14, 90), (10, 100)],\n",
    "              [(22, 90), (16, 100)],\n",
    "              [(30, 90), (24, 100)],\n",
    "              [(38, 90), (32, 100)],\n",
    "              [(46, 90), (40, 100)],\n",
    "              [(54, 90), (48, 100)]]\n",
    "\n",
    "trca_classifier = TRCA(sfreq, filterbank, True)\n",
    "test_accuracies = leave_one_block_evaluation(classifier=trca_classifier, X=eeg, Y=labels)\n",
    "test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4129396046028053"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg[0,0,0,0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPsNjpk5OuxKGuMR6xuEGQH",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Task-Related Component Analysis",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
